# AI

## 专业名词解释{AI、AIGC、AGI、NLP、LLM、GPT、ChatGPT}

- AI（人工智能）：计算机模仿并超越人类
- AIGC（AI生成内容）：利用AI技术生成的内容（文本、图像、音频、视频）
  - 互联网内容生产方式经历了PGC（专业生产内容）------UGC（用户生产内容）-----------AIGC（AI生成内容）
- AGI（通用人工智能）：创造一个能像人类一样思考、学习、执行多种任务的系统
- AGI与AIGC区别：AIGC指的是利用AI技术，尤其是机器学习和深度学习模型，自动生成内容，如文本、图像、音乐或视频。AIGC通常专注于特定的创作任务，而不具备AGI的广泛智能和通用学习能力。现阶段AGI仍然缺乏通用性和灵活性。
- NLP(自然语言处理)：让计算机读懂人类语言。NLP是人工智能和语言学领域的分支学科。
- LLM（大型语言模型）：LLM是 NLP 中的一个重要组成部分。主要是用来预测自然语言文本中下一个词或字符的概率分布情况，可以看作是一种对语言规律的学习和抽象。
  - 在NLP中，LLM是一种基本技术，用于处理和理解文本，包括词法分析、句法分析、语义分析等，广泛应用于机器翻译、自动问答系统、信息抽取、文本分类、情感分析等多个领域。而LLM，特别是基于Transformer架构的模型，如GPT-3和T5，通过大规模无监督学习来学习语言规律和上下文信息，然后在微调阶段根据具体任务进行有监督学习和优化，从而能够生成连贯、有意义的文本。这些模型的核心在于预训练和微调，预训练阶段使用掩码语言模型或下一句预测等技术，微调阶段则针对特定任务进行优化。
- AIGC涉及到的领域和技术很广泛，其中很重要的一项技术就是NLP(自然语言处理)，之所以把这3个概念放在一起描述，这两年来，AIGC取得了令人瞩目的增长，有很大因素就在于自然语言处理（NLP），而推动NLP发展到的就是LLM（大型语言模型），也就是我们接下来学习的重点，LLM。
- GPT（生成式预训练变换器）：GPT是NLP领域中的一个重要模型，它是基于Transformer架构构建的预训练语言模型。GPT（Generative Pre-trained Transformer）通过预先训练大量文本数据，学习到语言的基本结构和模式，从而能够理解自然语言文本的意义和语义。
- ChatGPT：ChatGPT是GPT在对话生成领域的特定应用。